Developing Game Strategy for Monopoly Using Genetic Algorithms
K. Mukhar, J K Kalita
  Abstract—Games are a rich field of study for artificial intelligence and evolutionary computation. A great deal of research has been conducted into using AI to solve deterministic games with complete information. However, research in non-deterministic games is more limited. This paper details study of the use of genetic algorithm techniques to evolve game strategies for the multi-player non-deterministic game Monopoly. Populations of Monopoly players were evolved using various chromosomes and fitness functions. The results showed that it was indeed possible to evolve players despite the high level of non-determinism and that the strategies that evolved tracked closely with heuristic rules used by real-world players.
I. INTRODUCTION
  In Theory of Games and Economic Behavior by Von Neumann and Morgenstern, games were used to model economics and economic behavior [1]. Early work by mathematicians studying card and dice games led to the development of statistics and probability [2], [3]. Games can be to study how social behavior and human interactions affect and are affected by game play [4]. A great deal of artificial intelligence research deals with developing AI game players and finding optimum game strategies [5].
  Early research into AI and games tended to focus on developing algorithms for searching the space of legal moves. This research led to such techniques as the Min-Max algorithm [1] and the A* search algorithm [6], [7].
  Researchers have used genetic algorithms and evolutionary computation to investigate whether optimal strategies for games can be evolved. Much of that research has focused on two player deterministic games like The Prisoner's Dilemma and Tic-Tac-Toe. Evolutionary computation techniques have been used with good success for these types of problems [8], [9], [10].
  However, there are other classes of games such as multi-player non-deterministic games where the search space is potentially quite large and the cost function could have multiple local and global optima. Evolutionary computation could be an effective approach to these types of problems because it provides the capability to traverse a large search space and find optimal strategies.
  This study investigates using evolutionary computation to evolve game strategies for these types of games. In general, this study evaluated whether genetic algorithms can be used to develop strategies for non-deterministic games. Specifically, genetic algorithms were applied to the non-deterministic game known as Monopoly to evolve game playing strategies.
  The rest of this paper is organized as follows. Section II reviews related research in applying genetic algorithms to various games from the relatively simple Prisoner’s Dilemma to more complicated games such as Othello. Section III presents a discussion of the game of Monopoly, focusing on the rules of the game and various heuristic strategies that have been developed since the game’s introduction. Based on the rules and heuristics, a genetic algorithm is designed and presented in Section IV. Section V presents the results of evolving a population of Monopoly players, using various fitness functions. Finally, Section VI summarizes the results and discusses future research directions.
II. BACKGROUND
  Holland, in his seminal work Adaptation in Natural and Artificial Systems, discussed applications of genetic algorithms to games [10]. Holland showed that the search space of many games quickly grew to a size that is not computationally tractable. He discussed how an artificial adaptive system (i.e., evolutionary computation) could be used to efficiently search the game space and realize an optimal strategy. Some of the research that applied Holland’s ideas to the study of games is summarized below.
A. Deterministic zero sum games
  One of the most studied games is the two person game known as the Prisoner's Dilemma, a game in which two players can either cooperate or defect, without the ability to communicate with each other. In a single iteration of this game, the best strategy for both players is to defect [12], [13]. However, studies have shown that when the game is played repeatedly between two or more players (known as the Iterated Prisoner's Dilemma game), a strategy of cooperation will evolve spontaneously [8], [9], [14], [15], [16].
  The game of Tic-Tac-Toe is a relatively simple two-player competitive game played on a 3x3 grid. Players alternately place a symbol, (usually one player plays X and the other plays O) on an open grid space; the winner is the player that manages to create a straight line (vertically, horizontally, or diagonally) of three of his own symbols. Fogel showed that genetic algorithms could be used to evolve neural networks to play the game [10]. The game also can be solved using a pure genetic algorithm, with the genome encoding the different game board permutations.
  In Checkers each player has 12 pieces that can move diagonally on a board divided into an 8x8 grid of squares. If one player's piece is adjacent to the opponent's piece, and there is a blank square on the opposite side of the opponent's piece, the player can jump that piece and remove the opponent's piece from the board. The winner is the player who removes all of the opponent's pieces from the board. Fogel and Chellapilla used a neural network that was optimized using evolutionary computing and then tested the network in an on-line tournament. Their evolved ANN player was able to play at Expert level [17], [18].
  Othello (also known as Reversi) is a two-player game where players take turns placing colored tokens on the board. The winner is the player who can get the most tokens of his color on the board. Play is complicated by the fact that a player can only place a token in a way that “captures” the opponent's tokens. This is done by placing a token adjacent to an opponent's token such that at least one of the opponent's tokens lies between the new token and one of the already placed tokens. When a player captures a line of the opponent's tokens, all of the opponent's tokens in that line change to the capturing player's color. Chong, et al., investigated evolving the evaluation function of a neural network to create an ANN that could play Othello [19].
  Even for games of much higher complexity, genetic algorithms have been used with success. Genetic algorithms have been applied to games such as Chess [20] and Go [21], [22].
  These deterministic, two-player, zero-sum games are widely studied because they are relatively simple to understand and play. Most of them have a relatively limited search space (Othello, Chess and Go being obvious exceptions), which makes them tractable to study and simulation. However, there is a whole class of games, with many examples that are non-deterministic, multi- player (but still usually zero-sum) games. While not as well studied as the two player games mentioned previously, there has been some research on using evolutionary computation to create winning strategies for these games.
B. Monopoly – A Non-Deterministic game
  Monopoly is a game where players traverse a path around a board on which most spaces represent a property (See Figure 1) which players can buy. Other players must pay “rent” to the owner of a property when they land on that property. When one player owns all the properties in a color group (a monopoly), the player can “develop” the properties by building houses or hotels. This increases the rent value which increases the odds that an opponent will not be able to pay the rent. If a player cannot pay rent, he must sell or mortgage properties, and if that is not possible, give their properties to the owner. The winner is the player who bankrupts the other players. One of the first studies of the game was a statistical analysis of which properties were more valuable to own [23]. Frayn used evolutionary computing to develop an efficient strategy for property valuation and property management [24]. Another important feature of Monopoly is the ability of players to trade different properties. Because of the random nature of a player's moves, it is improbable that a single player will be able to land on and buy all the properties in a group. So, players usually must trade with other players to gain a monopoly on a property group. Yasumura, et al., studied different negotiating strategies to identify the best way to conduct negotiations between players [25].
III. OVERVIEW OF THE GAME OF MONOPOLY
A. Rules of Monopoly 
  Monopoly is a board game that consists of a four-sided game board, with 40 spaces along the sides of the board where a player can land as they move around the board (See Figure 1). As players move around the board, they can buy and sell property using play money.
  All the players in the game start with $1500 at the corner space marked “GO.” Each player is represented by a game token on the board. The players take turns rolling two six-sided dice and moving their game token by as many spaces as the value of the dice. Thus, for each move, a player will move between 2 and 12 spaces.
  If a player rolls doubles the player moves the token, takes any actions necessary, and then the player is allowed a second roll of the dice. If the player rolls doubles on the second roll, the player is allowed a third roll. If the player rolls doubles a third time, they must move their token directly to the space marked “Jail.”
  There are 28 locations on the game board that can be bought by the players. The locations are divided into 22 streets grouped into 8 color groups, 4 railroads, and 2 utilities. If the player lands on an un-owned location, the player may buy the property. If the player declines to buy the property, the property is auctioned among all players (including the player who originally declined to buy the property). If the player lands on a property that is already owned, the player must pay rent to the owning player. 
  Once a player obtains all properties within a group, the properties can be “improved” by building houses or hotels on the property. Improved properties have a higher rent. 
  The other 12 locations on the board cannot be owned by any player. For this study, only one of those locations is important. That location is the corner space marked “Jail.” There are three circumstances that can send a player to Jail: drawing a special card marked “Go To Jail,” landing on the corner marked “Go To Jail”; or rolling doubles three times in a row in one turn.
  A player whose token is in Jail may, on their next turn, pay $50, roll the dice, and leave jail; or the player may choose to attempt to roll doubles to leave jail. If the player has not rolled doubles on the third attempt, the player must immediately pay $50 and move the number of spaces shown on the dice.
  The complete set of rules can be accessed at http://www.hasbro.com/common/instruct/monins.pdf.
B. Game Strategies
  In the past, the official web site for the game provided a list of useful game strategies. (accessible at http://web.archive.org/web/20080516095129/http://www.hasbro.com/games/kid-games/monopoly/default.cfm?page= StrategyGuide/play_to_win). Some of those strategies are as follows: 
1) Buy a property if no other player owns a property in its color group.
2) Buy a property if it gives you a second or third property of its group.
3) Buy a property if it blocks an opponent from controlling a color group.
4) Buy a property if it is an orange property (always block this group if you can).
5) Pay $50 and get out of Jail early in the game while many MONOPOLY properties remain un-owned and undeveloped.
6) When most MONOPOLY properties are developed between Jail and the Go to Jail space, roll the dice and hope to stay in Jail.
IV. METHODOLOGY
  A survey of previous research found only two computer science papers: the previously cited study by Frayn [24] of using evolutionary computing to evolve property evaluations, and the study by Yasumura, et al., of negotiating strategies [25]. In addition, there have been analytical studies and Monte Carlo simulations of the statistics and probability of landing on any particular location in Monopoly [23].
  A finite state machine was used to model player actions. In many cases, the transition from state to state is made automatically without input from the player. For example, a player always has to roll the dice to move around the board; this event does not require any input or decision from the player. However, analysis of the state machine revealed four state transitions that do require a decision on the part of the player.
1) The player must decide whether or not to buy a property. If a property is being auctioned, the player must decide whether and how much to bid for the property.
2) The player must decide whether to pay bail and exit jail immediately, or roll the dice and wait until doubles are rolled.
3) The player must decide when and how to buy houses or hotels for their properties.
4) The player must decide if and when to trade for properties to complete a monopoly.
  Based on the rules of Monopoly and previous analytic studies, the following focus areas were enumerated.
1) Decisions on whether to buy a property depend on what other properties have been acquired and which players have acquired them.
2) The decision of whether to stay in jail or leave jail depends on what other properties have been acquired and which players have acquired them.
3) There are a limited number of buildings in the game. Whether one can build depends on what other players have built, and vice versa.
4) The ability to develop a property group depends on the ability of the player to acquire all the properties in a group. This is done by trading with other players.
  These focus areas resulted in a preliminary decision to use a multiple chromosome strategy in which different chromosomes control the player behavior depending on the state of the game: one strategy for early in the game when few properties are owned; a different strategy for later in the game when many properties are owned. Frayn used a similar strategy, except in his study, the valuation of a property depended on ownership and development factors and the genome used that valuation to make decisions. 
  Additionally, this study focused on just two decisions that the player would make: the buy property decision (item 1 from the list above) and the get out of jail decision (item 2). The other two decisions, whether to build a house (item 3) and whether to trade a property (item 4), were not implemented using genetic computation. The house building decision was implemented as a rule based algorithm; the property trading decision was not implemented.
A. Chromosome description
  The genome for the evolved player consists of multiple chromosomes; each chromosome is used for a different purpose or state of the game. This is in contrast to the classic simple GA where each member of the population has a single chromosome that is expressed as a string of binary digits. Following the initial description of the primary chromosome used in this study, two alternate versions of the chromosome will be described.
  The first set of chromosomes consists of 4 arrays of doubles, 40 elements per array (See Figure 2). In this paper, this chromosome is referred to as the RGA Player (RGA for Real-valued Genetic Algorithm). Each element of the array represents the probability that the player will purchase the property represented by the array element. There are 40 locations on the monopoly board, so each location corresponds to an element in the array. The “Go” space is element 0, with subsequent locations assigned successive element indices. However, only 28 locations can be owned by a player, so 12 of the array elements are ignored. The chromosome could have contained only 28 locations, but by using 40 elements, the need to create a mapping between locations and array elements is avoided (for improved code readability and maintainability) at a small cost of memory for the 12 unused elements. Each array corresponds to one of the following game states.
1) The first array is used when no player owns any property in the group where the player is currently located.
2) The second array is used when the current player owns at least one property in the group where the player is currently located and no other player owns property in that group.
3) The third array is used when one other player owns property in the property group where the player is currently located.
4) The fourth array is used when two other players both own property in the property group where the player is currently located. Based on the game strategies listed earlier the 4th chromosome will tend to have values that are generally less than the values in the 1st, 2nd and 3rd chromosomes. That is, the player should be more likely to buy property when no other player owns any properties in the group (1st chromosome), when the property is needed to complete a monopoly (2nd chromosome), and when the property is needed to block another player (3rd chromosome).
  The other set of chromosomes is used to determine when to pay to get out of jail, and when to remain in jail (and hopefully not roll doubles with the dice). This chromosome is a 2-D array of doubles.
  Rows and columns in the array are indexed by 6-bit numbers created by the properties on one side of the board. The first index corresponds to the West side of the board; the second index corresponds to the North side of the board. For each property on the West/North side of the board, the corresponding bit in the index is set to 1 if the property is owned by some other player; otherwise, it is set to 0. Thus there are two indices with values that range from 0 to 63.
  The value at each element of the array is a double which represents the probability that the player will choose to pay the bail. Note that this scheme automatically accounts for different game states: early in the game, very few of the properties are owned (none when the game begins) so the indices will be near (0, 0); later in the game, if many properties are owned by other players, the indices will be near (63, 63). It also accounts for differences in ownership. That is, if opponents own many properties on the West and North edges, the indices will be relatively high, whereas if the player owns many of the properties, the indices will be relatively low. So, if the player owns properties near the jail, his jail decision will be similar to the decision made early in the game when few properties are owned.
B. Alternate Jail Chromosome
  Because the 64x64 array described above consumes a relatively large amount of memory, this study also looked at an alternate genome which varied the “Get Out Of Jail” chromosome by making it a 4x4 array. Instead of indexing by which players owned properties on the West and North edges of the board, the index was created by determining if any of the four groups are part of a monopoly owned by an opponent. This only requires a two-bit index and 16 array elements. The player using this chromosome will be referred to as the TGA Player. 
C. Alternate Chromosome description
  Goldberg described the structure of a simple GA (SGA) in Genetic Algorithms in Search, Optimization, and Machine Learning [26]. The SGA uses a single string of binary bits for its chromosome. Although the primary population used in this study consists of real valued chromosomes described above, the same information could be encoded into binary strings.
  We start by converting each element (gene) in the original chromosome into a 6 bit number. Each element in the original chromosome now has a value that ranges from 0 to 63, or a coarseness of approximately 1.6% for each decision. Then we take all the genes and concatenate them into a single string. So, for example, the first chromosome of 40 elements becomes a single string of 240 bits (6 bits * 40 elements). Each of the other property buying chromosomes is encoded in the same way.
  The “Get Out Of Jail” chromosome is then encoded as a 96 bit string (16 genes x 6 bits per gene). This chromosome uses the simplified indexing scheme described previously in Section C.
D. Population Evolution 
  Following Frayn [24], Table I shows the genetic algorithm parameters used for creating and evolving the population of game players.
E. Fitness Evaluation
  Five different fitness evaluations were used for the genetic algorithm. The winner of each game is the last player left in the game, or the player with the greatest net worth when the game finishes. The second place player is the second to last player in the game, or the player with the second greatest net worth when the game finishes. Third and fourth place players are determined similarly. The different evaluators awarded points to the players as follows.
1) Number of wins (NUM_WINS); the winner of each game receives three points; all other players receive zero points.
2) Number of Properties owned (NUM_PROPERTIES); each player receives one point per property owned at the end of the game.
3) Number of Monopolies (NUM_MONOPOLIES); each player receives one point for each monopoly they control.
4) Finish Order (FINISH_ORDER); in a game with n players, the winner of the game receives n1 points; second place receives n2 points, and so on. The last place finisher receives 0 points.
5) Net Worth (NET_WORTH); at the end of each game, the net worth of each player is calculated. Each player receives points that equal their net worth/100.
F. Procedure
  The genetic algorithm proceeds as follows:
1) Initialize a population of 1000 individuals.
2) At the start of a generation, the 1000 individuals are randomly divided into 250 sets of 4.
3) These 250 sets each play an individual game. At the conclusion of each game, the fitness evaluator for that population computes points for the game and adds the points to the player’s fitness score. After all 250 games are complete, the 1000 individuals are again randomly divided into 250 different sets, and the sets play again until each player has played 100 games.
4) At the end of the generation, the total number of points earned by each individual is evaluated as the fitness of the individual.
5) The new population of 1000 players is created using this procedure:
a. the top 10% (approximately 100 players) survive to the next generation;
b. three hundred more (30%) survive based on a roulette selection with replacement;
c. three hundred more (30%) are selected based on a roulette selection with replacement and then mutated for the next generation;
d. the final 300 individuals are created by selecting parents using roulette wheel selection, and then combing the chromosomes to create two new children. For the RGA and TGA players with real-valued chromosomes, the child chromosomes are created by blending each parent gene using these formulas from [27]:

child1 = ?parent1 + (1-?)parent2
child2 = (1-?)parent1 + ?parent2

6) When the new population is complete, return to step 2.
V. RESULTS
A. RGA Player
  The Monopoly simulation was run for 1000 generations using each combination of chromosomes and fitness evaluators. To try to reduce the stochastic effects of any single game, each generation consisted of 100 matches. Since there were 1000 individuals and each game was simulated with 4 players, every match consisted of 250 games. Every player played 100 games per generation, and there were a total of 25,000 games were played in each generation.
  Unlike other genetic computing processes where the average and best fitness improves as the population evolves, the expected results for this study are different. Since fitness is measured relative to other players in a game, the fitness distribution will tend to look like a binomial distribution. For example, suppose the fitness measure NUM_WINS is used with a population where one player in the population wins all 100 games in a generation. As the population evolves, other players will get better and it will be less likely that the one perfect player can still win 100 games. If one assumes that population evolution results in a population where all players eventually evolve a perfect strategy, then within that population some players must still lose some games since they are playing against other players that also have perfect strategy. This will occur regardless of which of the five fitness measures is used.
  Since the first generation is randomly created, it is expected that the players will be randomly spread in their ability to win games. So on average in the initial generation, some players will win less than half the games they play, most will win about half the games they play, and some players will win more than half. Thus the distribution of fitness scores will follow a distribution similar to the binomial distribution (See Figure 3).
  When the initial population of players was run through a single generation, the actual results matched the expected results quite closely. Thirty populations were initialized and run through a single generation. Using the FINISH_ORDER fitness evaluation, the average population fitness for the 30 trials after 1 generation was 149.962. The distribution of fitness scores from one of the trials is shown in Figure 4. The same experiment was run with the other fitness evaluators with similar results: the fitness plot resembled a binomial distribution centered on an average fitness (although in the case of NET_WORTH it was very flat since it was highly unlikely that players would have identical net worth values in any generation).
  As a population evolves the average and best fitness scores are not expected to increase. Rather the average fitness will remain at the same value (depending on the fitness evaluator), and the worst and best fitness scores should tend to converge towards the average. As poor players are removed from the population, the remaining players will tend to be near each other in ability. Thus, the distribution of fitness scores will become much tighter around the average score, and no single player will be able to dominate the other players.
  Figure 5 shows the actual fitness distribution at generation 100 of an RGA population using the FINISH_ORDER fitness evaluator. As predicted, it can be seen that the mean remained approximately the same, but the deviation from the mean has decreased. Whereas the fitness scores in generation 0 range from 92 to 204, in generation 100 they range from 112 to 184. The distribution around the mean tightened relatively quickly (it can clearly be seen in generation 100), and did not get significantly tighter over the course of the simulation which was 1000 generations.
  The genome for the fittest player in generation 1000 is shown in Figure 6. In general, the genome matches the heuristic strategy described previously. In general, the gene values for buying a location are higher when a player already owns one of the properties of a group compared to when two other players own properties in the group. Although it is not shown in Figure 6, the gene values for buying when one opponent owns are generally higher than when two opponents own a property in the group.
  When compared to the strategy list from Section IV, there might appear to be an inconsistency in the genome. The strategy says always buy a property if no one else owns it. Only the gene value for Park Place approaches a probability of 1.0 which is implied by the strategy. This can easily be explained by the fact that if the player declines a property with probability p, the probability of subsequently buying the property is higher. This is because when a player declines a property, it is then auctioned to any player including the declining player. Since the declining player makes the bid decision based on the same chromosome, the probability of buying the property then becomes
  
  Pbuy = 1 - (1 - Pbuy)(1 - Pbuy)
  
  That is, when a player does not buy a property, the player to must decline to buy it twice (i.e., decline to buy and then decline to bid for property in the auction). Since these are independent events, the probability of not buying is approximately Pdecline*Pdecline. The probability of buying is then actually 1 minus not buying. Thus, even when the probability of buying is as low as 0.6, the probability of declining is 0.4, and the probability of obtaining the property becomes 0.84.
B. SGA Player
  After evolving the population of RGA Players, the simulation was conducted again using SGA Players. SGA players are those players with a binary string chromosome.
  The fitness distribution in the first generation shows the same general similarity to the binomial distribution (Figure 7), although the distribution appears to be skewed slightly. 
  Figure 8 shows the fitness distribution at generation 289 and the skew is definitely present. It is unclear why this would have occurred. 
C. TGA Player
  Finally, the same simulation was conducted using 1000 TGA players. (Whereas the R in RGA stood for Real, and the S in SGA was for Simple, the T in TGA does not have any meaning other than it follows R and S).
  The results for the TGA player were essentially the same as for the RGA player. The fitness distribution had the same shape as the RGA fitness distribution, with similar minimums and maximums. Over the 1000 generations, the fitness distribution converged towards the mean fitness. The player genomes were also very similar. This leads to the conclusion that the fitness depends primarily on buying property (in which the RGA and TGA genomes are identical), and not on when or how to get out of jail which was the difference between the two genomes.
VI. CONCLUSIONS
  This study showed that evolutionary computing can be used to evolve players for the non-deterministic game Monopoly. These players also appear to use strategies similar to those that have been developed heuristically by real-world players. However, more real world testing is needed to see if the evolved players are indeed good players.
  Based on the results and other questions encountered during this study, additional research can be conducted in the following areas:
1) As discussed above, the average fitness did not increase over time even if the players were getting better. Future work could attempt to create absolute fitness evaluators rather than the current relative evaluators.
2) Several of the evolved high fitness players could be played against real or AI players to evaluate the real (rather than simulated fitness) of the population.
3) The literature on Monopoly states that making property trades is a vital part of the game. This functionality could be implemented and tested to see if the evolved players do better when they can trade properties to create monopolies.
4) The fitness distribution for the SGA player diverged from the mean rather than converged as was expected. This behavior could be investigated to determine whether this is an anomaly or if there is some logical reason for this.
APPENDIX
  The code used to run the genetic algorithm is available at http://github.com/kmukhar/GAMonopoly.
REFERENCES
[1] Von Neumann, J., Morgenstern, O., Theory of games and economic behavior. New York, NY, John Wiley & Sons, Inc., 1944.
[2] Hald, A., A history of probability and statistics and their applications before 1750, Hoboken, NJ, John Wiley & Sons, 2003, pg 4.
[3] Rudas, T., Handbook of Probability: Theory and Applications, Thousand Oaks, CA, SAGE Publications, 2008, pg 4.
[4] Fararo, T. J., The Meaning of General Theoretical Sociology: Tradition and Formalization, New York, NY, Cambridge University Press, 1992.
[5] Russell S.J., Norvig P., Canny J.F., Artificial Intelligence: A Modern Approach, Upper Saddle River, NJ, Prentice Hall, 2003.
[6] Hart, P. E.; Nilsson, N. J.; Raphael, B. "A Formal Basis for the Heuristic Determination of Minimum Cost Paths". IEEE Transactions on Systems Science and Cybernetics SSC4 (2), 1968, pp. 100–107.
[7] Flood, M.M., Some experimental games. Research memorandum RM-789. RAND Corporation, Santa Monica, CA. 1952
[8] Nowak, M., Sigmund, K., “A strategy of win-stay, lose-shift that outperforms tit-for-tat in the Prisoner's Dilemma game.” Nature. Vol. 364, no. 6432, pp. 56-58. 1993.
[9] Quek, H.Y., Goh C.K., “Adaptation of Iterated Prisoner's Dilemma Strategies by Evolution and Learning,” IEEE Symposium on Computational Intelligence and Games, 2007. CIG 2007, pp.40-47.
[10] Fogel, D.B., “Using evolutionary programming to create neural networks that are capable of playing tic-tac-toe,” IEEE International Conference on Neural Networks, 1993., vol. 2, no., pp.875-880, 1993
[11] Holland, J.H., Adaptation in Natural; and Artificial Systems. Cambridge, MA: MIT Press, 1992, pp 40-44, 132-136.
[12] Nash, J.  "Equilibrium points in n-person games" Proceedings of the National Academy of Sciences 36(1):48-49, 1950.
[13] Nash, J., "Non-Cooperative Games" The Annals of Mathematics 54(2):286-295. 1951.
[14] Axelrod, R., The Evolution of Cooperation, New York, NY, Basic Books, 1984
[15] S. Mittal and K. Deb, “Optimal strategies of the iterated prisoner's dilemma problem for multiple conflicting objectives,” Evolutionary Computation, IEEE Transactions on, vol. 13, pp. 554-565, June 2009.
[16] W. Tao, C. Zhi-Gang, D. Xiao-Heng, and Z. Jin, “Properties of prisoner's dilemma game based on genetic algorithm,” in Control Conference (CCC), 2010 29th Chinese, pp. 4732-4736, July 2010.
[17] Chellapilla, K., Fogel, D.B., “Anaconda defeats Hoyle 6-0: a case study competing an evolved checkers program against commercially available software,” Proceedings of the 2000 Congress on Evolutionary Computation, vol.2, pp.857-863, 2000
[18] Chellapilla, K., Fogel, D.B., “Evolving an expert checkers playing program without using human expertise,” IEEE Transactions on Evolutionary Computation, vol. 5, no. 4, pp. 422 – 428, 2001.
[19] Chong, S.Y.; Tan, M.K.; White, J.D., “Observing the evolution of neural networks learning to play the game of Othello,” IEEE Transactions on Evolutionary Computation, vol.9, no.3, pp. 240-251, June 2005
[20] T. Mitsuta and L. M. Schmitt, “Optimizing the performance of gnu-chess with a genetic algorithm,” in Proceedings of the 13th International Conference on Humans and Computers, HC '10, (Fukushima-ken, Japan, Japan), pp. 124-131, University of Aizu Press, 2010.
[21] S. M. Shah, D. Singh, and J. Shah, “Using genetic algorithm to solve game of go-moku,” IJCA Special Issue on Optimization and On-chip Communication, vol. ooc, pp. 28-31, February 2012. Published by Foundation of Computer Science, New York, USA.
[22] T. Blackman and A. Agah, “A multi-agent approach to the game of go using genetic algorithms," Journal of Intelligent Systems, vol. 18, no. 1-2, pp. 143-169, 2009.
[23] Ash, R. B., and Bishop, R. L. 1972. “Monopoly as a Markov process.” Mathematics Magazine 45:26-29
[24] Frayn, C.M., “An evolutionary approach to strategies for the game of monopoly”, Proceedings of IEEE Symposium on Computational Intelligence and Games, 2005, CIG 2005, pp 66–67.
[25] Yasumura, Y.; Oguchi, K.; Nitta, K., "Negotiation strategy of agents in the MONOPOLY game," Proceedings of 2001 IEEE International Symposium on Computational Intelligence in Robotics and Automation, 2001
[26] D. Goldberg, Genetic algorithms in search, optimization, and machine learning. Artificial Intelligence, Addison-Wesley Pub. Co., 1989.
[27] Adewuya, A. A., New Methods in genetic search with real-valued chromosomes. Master’s Thesis. Massachusetts Institute of Technology, Cambridge, MA, 1996.
   K. Mukhar is a Master’s Degree candidate at the University of Colorado Colorado Springs, CO 80918 USA (phone: 408-475-6854; e-mail: kmukhar@uccs.edu).
   J. K. Kalita is with the Department of Computer Science, University of Colorado Colorado Springs, CO 80918 USA. (e-mail: jkalita@uccs.edu).
   Monopoly is a registered trademark of Hasbro, Inc.


------------------------------------------------------------

---------------

------------------------------------------------------------





